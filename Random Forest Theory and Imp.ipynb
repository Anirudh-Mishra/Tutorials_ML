{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Random Forest</h1>\n",
    "<br>    So, now that we have covered decision trees, in this tutorial we will cover Random Forest, another algorithm that makes use of decision trees but is more efficient. As the names of the algorithm suggests, we make use of multiple decision trees in a single algorithm constituting a forest to help us perform classification or regression. Let me clarify the concept with the help of an example.<br><br> \n",
    "    \n",
    "<i>Suppose you want the name of a good movie to watch. You ask one of your friends for a suggestion. He asks you a bunch of questions(such as which movies you have watched before, how you liked them etc.) and based on your answers gives you a suggestion. But you are still not satisfied and head to other friends of yours for suggestions. Your other friends ask you a bunch of other questions some of which might be similar to the previous ones asked but no two sets of questions asked will turn out to be completely identical. In the end, you pick the most suggested movie.</i>\n",
    "<br><br>That is how the Random Forest algorithm works too. Simply put, it makes use of random multiple decision trees and in the end, the prediction is made based on the most returned target. The low correlation between models is the key. Uncorrelated models can produce ensemble predictions that are more accurate than any of the individual predictions. The reason for this wonderful effect is that the trees protect each other from their individual errors (as long as they donâ€™t constantly all err in the same direction). While some trees may be wrong, many other trees will be right, so as a group the trees are able to move in the correct direction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](image.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the next question arises, how do we ensure lower correlation among the numerous decision trees in our forest? The following two methods are used :-\n",
    "    <ul>\n",
    "    <li><h5>Bagging(Bootstrap Aggregation)</h5> In this method, all the features are considered for all trees. However, the tree is allowed to sample from the dataset with replacement randomly. For example, say the dataset consists of [1,2,3,4,5,6]. One of the trees samples data as [1,2,2,4,4,6]. Even though both the sizes of the original data and the sample taken by the tree is 6, the data varies in both since in the tree's sample, replacements are also considered. This creates a lot of random possibilities minimizing correlation between numerous trees.</li>\n",
    "    </ul>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](example.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul><li><h5>Feature Randomness</h5> In this method, all the trees are assigned random subsets of features individually resulting in lower correlation and more diversification. For example, our dataset consists of four features, namely 1,2,3 and 4. Let us consider two trees for explanation. The first tree might only consider features 2 and 3 for splitting since that might by the only features assigned to the tree randomly and even though feature 1 would be the best feature to carry out a split, the first tree will not be able to view it since it wouldn't be assigned that feature. The second tree might consider 1 and 3 for splitting. As we can see this feature variation would lead to different splitting in the long run and hence result in lower correlation.</li></ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving on, a basic overview of the working of our Random Forest is as follows -:\n",
    "    <ul>\n",
    "        <li><b>Step 1</b> : Takes the test features and use the rules of each randomly created decision tree to predict the outcome and stores the predicted outcome (target).</li>\n",
    "        <li><b>Step 2</b> : Calculate the votes for each predicted target.</li>\n",
    "        <li><b>Step 3</b> : Consider the high voted predicted target as the final prediction from the random forest algorithm.</li><br>\n",
    "    That's all for the theoretical background on Random Forest. Let us move on to its implementation.\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Classification</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np                                                                      # For preprocessing\n",
    "from sklearn.model_selection import train_test_split                                    # For splitting of data\n",
    "from sklearn.preprocessing import StandardScaler                                        # For feature scaling\n",
    "from sklearn.ensemble import RandomForestClassifier                                     # For the RandomForest classification model\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score     # For accuracy, precision, recall and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Bill_authentication.csv')\n",
    "X = data.iloc[:,:-1].values                                                  # Stores features and target in variables\n",
    "y = data.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)          # Splits data into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)                                          # Feature scaling\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestClassifier(n_estimators=20, random_state=0)                # Model will consist of 20 decision trees\n",
    "regr.fit(X_train, y_train)                                                   # Building and fitting the model\n",
    "y_pred = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[155   2]\n",
      " [  1 117]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       157\n",
      "           1       0.98      0.99      0.99       118\n",
      "\n",
      "    accuracy                           0.99       275\n",
      "   macro avg       0.99      0.99      0.99       275\n",
      "weighted avg       0.99      0.99      0.99       275\n",
      "\n",
      "0.9890909090909091\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred.round()))                               # Shows the confusion matrix\n",
    "print(classification_report(y_test,y_pred.round()))                          # Shows detailed report of precision and recall\n",
    "print(accuracy_score(y_test, y_pred.round()))                                # Shows accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Regression</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor             # For the RandomForest regression model\n",
    "from sklearn.model_selection import train_test_split           # For splitting the data\n",
    "from sklearn.preprocessing import StandardScaler               # For feature scaling\n",
    "from sklearn import metrics                                    # For finding errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Petrol_consumption.csv')\n",
    "X = data.iloc[:,:-1].values                                    # Preprocessing\n",
    "y = data.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)         # Splitting data into test and training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)                   # Feature scaling of both test and training sets\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = RandomForestRegressor()\n",
    "regr.fit(X_train,y_train)                             # Fitting the model to train set and finding corresponding outputs of test set\n",
    "y_out = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 50.40599999999999\n",
      "Mean Squared Error: 3713.575819999998\n",
      "Root Mean Squared Error: 60.93911568114521\n"
     ]
    }
   ],
   "source": [
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_out))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_out))                   # Printing the error \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_out)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
